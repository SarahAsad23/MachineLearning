{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8a02943d"
   },
   "source": [
    "# CS273A Homework 5\n",
    "\n",
    "## Due: Wednesday Nov 20 2024 (11:59pm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09c60894"
   },
   "source": [
    "---\n",
    "## Instructions\n",
    "\n",
    "\n",
    "This homework (and subsequent ones) will involve data analysis and reporting on methods and results\n",
    "using Python code. You will submit a **single PDF file** that contains everything to Gradescope. This includes any text you wish to include to describe your results, the complete code snippets of how you attempted each problem, any figures that were generated, and scans of any work on paper that you wish to include. It is important that you include enough detail that we know how you solved the problem, since otherwise we will be unable to grade it.\n",
    "\n",
    "Your homeworks will be given to you as Jupyter notebooks containing the problem descriptions and some template code that will help you get started. You are encouraged to use these starter Jupyter notebooks to complete your assignment and to write your report. This will help you not only ensure that all of the code for the solutions is included, but also will provide an easy way to export your results to a PDF file (for example, doing *print preview* and *printing to pdf*). I recommend liberal use of Markdown cells to create headers for each problem and sub-problem, explaining your implementation/answers, and including any mathematical equations. For parts of the homework you do on paper, scan it in such that it is legible (there are a number of free Android/iOS scanning apps, if you do not have access to a scanner), and include it as an image in the Jupyter notebook.\n",
    "\n",
    "**Double check that all of your answers are legible on Gradescope, e.g. make sure any text you have written does not get cut off.**\n",
    "\n",
    "If you have any questions/concerns about using Jupyter notebooks, ask us on EdD. If you decide not to use Jupyter notebooks, but go with Microsoft Word or LaTeX to create your PDF file, make sure that all of the answers can be generated from the code snippets included in the document.\n",
    "### Summary of Assignment: 100 total points\n",
    "- Problem 1:  Decision Trees by Hand (25 points)\n",
    "    - Problem 1.1:  Shannon Entropy (5 points)\n",
    "    - Problem 1.2:  Information Gain (10 points)\n",
    "    - Problem 1.3:  Full Tree (10 points)\n",
    "- Problem 2: Decision Trees in Python (34 points)\n",
    "    - Problem 2.1: Feature Statistics (8 points)\n",
    "    - Problem 2.2: Initial Tree (6 points)\n",
    "    - Problem 2.3: Exploring Depth Control (10 points)\n",
    "    - Problem 2.4: Exploring Leaf Size (10 points)\n",
    "- Problem 3: Random Forests (20 points)\n",
    "    - Problem 3.1: Training Members (10 points)\n",
    "    - Problem 3.2: Ensemble Prediction (10 points)\n",
    "- Problem 4: VC Dimension (16 points)\n",
    "    - Problem 4.1: Model A (4 points)\n",
    "    - Problem 4.2: Model B (4 points)\n",
    "    - Problem 4.3: Model C (4 points)\n",
    "    - Problem 4.4: Model D (4 points)\n",
    "- Statement of Collaboration (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7b721e2a"
   },
   "source": [
    "Before we get started, let's import some libraries that you will make use of in this assignment. Make sure that you run the code cell below in order to import these libraries.\n",
    "\n",
    "**Important: In the code block below, we set `seed=1234`. This is to ensure your code has reproducible results and is important for grading. Do not change this. If you are not using the provided Jupyter notebook, make sure to also set the random seed as below.**\n",
    "\n",
    "**Important: Do not change any codes we give you below, except for those waiting for you to complete. This is to ensure your code has reproducible results and is important for grading.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 445,
     "status": "ok",
     "timestamp": 1700601893926,
     "user": {
      "displayName": "Samuel Showalter",
      "userId": "14379346311603786226"
     },
     "user_tz": 480
    },
    "id": "1e3be6e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests                                      # reading data\n",
    "from io import StringIO\n",
    "\n",
    "from sklearn.datasets import fetch_openml            # common data set access\n",
    "from sklearn.preprocessing import StandardScaler     # scaling transform\n",
    "from sklearn.model_selection import train_test_split # validation tools\n",
    "from sklearn.metrics import zero_one_loss as J01\n",
    "\n",
    "import sklearn.tree as tree\n",
    "\n",
    "# Fix the random seed for reproducibility\n",
    "# !! Important !! : do not change this\n",
    "seed = 1234\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dc194425"
   },
   "source": [
    "---\n",
    "## Problem 1: Decision Trees for Spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08db9a1a"
   },
   "source": [
    "In order to reduce my email load, I decide to implement a machine learning algorithm to decide whether or not I should read an email, or simply file it away instead.  To train my model, I obtain the following data set of binary-valued features about each email, including whether I know the author or not, whether the email is long or short, and whether it has any of several key words, along with my final decision about whether to read it ($y=+1$ for \"read\", $y=-1$ for \"discard\").\n",
    "\n",
    "| X1 | X2 | X3 | X4 | X5 | y |\n",
    "|----|----|----|----|----|----|\n",
    "| (know author?) | (is long?)| (has 'research'?) | (has 'grade'?) | (has 'lottery'?) | (read?) |\n",
    "| 0  | 0  | 1  | 1  | 0  | -1 |\n",
    "| 1  | 1  | 0  | 1  | 0  | -1 |\n",
    "| 0  | 1  | 1  | 1  | 1  | -1 |\n",
    "| 1  | 1  | 1  | 1  | 0  | -1 |\n",
    "| 0  | 1  | 0  | 0  | 0  | -1 |\n",
    "| 1  | 0  | 1  | 1  | 1  |  1 |\n",
    "| 0  | 0  | 1  | 0  | 0  |  1 |\n",
    "| 1  | 0  | 0  | 0  | 0  |  1 |\n",
    "| 1  | 0  | 1  | 1  | 0  |  1 |\n",
    "| 1  | 1  | 1  | 1  | 1  | -1 |\n",
    "\n",
    "In the case of any ties where both classes have equal probability, we will prefer to predict class $+1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63733bef"
   },
   "source": [
    "Solve the following problems \"by hand\" (you can use python for logarithms, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cfbce3f"
   },
   "source": [
    "### Problem 1.1   (5 points)\n",
    "\n",
    "**Calculate the Shannon entropy** $H(y)$ of the binary class variable $y$, in bits.  **Hint:** Your answer should be a number between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700601894221,
     "user": {
      "displayName": "Samuel Showalter",
      "userId": "14379346311603786226"
     },
     "user_tz": 480
    },
    "id": "1f4e32ba"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fd05e2ac"
   },
   "source": [
    "### Problem 1.2  (5 points)\n",
    "\n",
    "**Calculate the information gain** for each feature $x_i$.  Which feature should be split first?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1700601894839,
     "user": {
      "displayName": "Samuel Showalter",
      "userId": "14379346311603786226"
     },
     "user_tz": 480
    },
    "id": "031defba"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fd292650"
   },
   "source": [
    "### Problem 1.3  (5 points)\n",
    "\n",
    "**Draw** (or otherwise illustrate) **the complete decision tree** that will be learned from these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1700601895485,
     "user": {
      "displayName": "Samuel Showalter",
      "userId": "14379346311603786226"
     },
     "user_tz": 480
    },
    "id": "ccb85fde"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8d8abe82"
   },
   "source": [
    "<div>\n",
    "    <img src=\"data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22UTF-8%22%20standalone%3D%22no%22%3F%3E%0A%3C%21DOCTYPE%20svg%20PUBLIC%20%22-//W3C//DTD%20SVG%201.1//EN%22%20%22http%3A//www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd%22%3E%0A%3Csvg%20stroke-miterlimit%3D%2210%22%20style%3D%22fill-rule%3Anonzero%3Bclip-rule%3Aevenodd%3Bstroke-linecap%3Around%3Bstroke-linejoin%3Around%3B%22%20version%3D%221.1%22%20viewBox%3D%220%200%20288%2072%22%20xml%3Aspace%3D%22preserve%22%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20xmlns%3Axlink%3D%22http%3A//www.w3.org/1999/xlink%22%3E%0A%3Cdefs/%3E%0A%3Cg%20id%3D%22Layer-1%22%3E%0A%3Cpath%20d%3D%22M34.042%2035.8741C45.8469%2023.244%2031.1794%2022.6473%2024.2857%2024.1167C17.3921%2025.5861-0.960215%2033.2987%206.07817%2043.4256C13.1166%2053.5525%2023.0237%2056.9377%2052.2446%2053.4091C81.4656%2049.8804%2097.2436%2032.811%20122.962%2029.3111C148.681%2025.8112%20155.118%2039.4093%20155.118%2039.4093%22%20fill%3D%22none%22%20opacity%3D%221%22%20stroke%3D%22%23000000%22%20stroke-linecap%3D%22butt%22%20stroke-linejoin%3D%22round%22%20stroke-width%3D%223%22/%3E%0A%3Cpath%20d%3D%22M254.053%2040.6889C242.328%2053.1071%20256.999%2053.6247%20263.883%2052.1549C270.768%2050.685%20289.071%2043.0512%20281.969%2033.1691C274.868%2023.287%20264.94%2020.0179%20235.741%2023.6051C206.543%2027.1922%20190.872%2043.9744%20165.176%2047.5176C139.48%2051.0607%20132.957%2037.7776%20132.957%2037.7776%22%20fill%3D%22none%22%20opacity%3D%221%22%20stroke%3D%22%23000000%22%20stroke-linecap%3D%22butt%22%20stroke-linejoin%3D%22round%22%20stroke-width%3D%223%22/%3E%0A%3C/g%3E%0A%3C/svg%3E%0A\" width=\"200\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67d218cb"
   },
   "source": [
    "## Problem 2: Decision trees in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "496c697a"
   },
   "source": [
    "In the next problem, we will use decision trees to predict a data set used for Kaggle competitions in older iterations of the course; see e.g.,\n",
    "https://www.kaggle.com/c/uc-irvine-cs273a-2016\n",
    "\n",
    "Note that I have altered the data from that competition to make the target variables +1 and -1, instead of 0/1, to better match some of the ensemble slides.\n",
    "\n",
    "First, let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2310,
     "status": "ok",
     "timestamp": 1700602148369,
     "user": {
      "displayName": "Samuel Showalter",
      "userId": "14379346311603786226"
     },
     "user_tz": 480
    },
    "id": "923d3650",
    "outputId": "02c52dc3-8f93-4469-896b-c83a1205091b"
   },
   "outputs": [],
   "source": [
    "url = 'https://www.ics.uci.edu/~ihler/classes/cs273/data/precip_train.txt'\n",
    "\n",
    "with requests.get(url, verify=False) as link:\n",
    "  data = np.genfromtxt(StringIO(link.text),delimiter=None)\n",
    "\n",
    "X,Y = data[:,:-1], data[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ac1c910"
   },
   "source": [
    "#### Problem 2.1\n",
    "Compute and print some useful statistics about the data -- the minimum, maximum, mean, and variance of each of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ac1c910"
   },
   "source": [
    "In past assignments, we have first normalized the data (subtracting the mean and scaling each feature).  We will not do that here, however. Why is that step unnecessary for our decision tree model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "561a4237"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29ecfd60"
   },
   "source": [
    "#### Problem 2.2\n",
    "To allow faster experimentation, select the first 10,000 data points as training data, ``Xtr, Ytr``, and the next 10,000 data points as validation, ``Xva, Yva``.  Then, learn a decision tree classifier on ``Xtr`` using the ``DecisionTreeClassifier`` class from ``scikit-learn``.  Use a large depth, say ``max_depth=100``, and the Shannon entropy impurity function in your training.  Also, use ``random_state=seed`` to ensure consistency.\n",
    "\n",
    "Compute and print out the training error rate and validation error rate of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3bee9cda"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3213ff99"
   },
   "source": [
    "#### Problem 2.3\n",
    "Now try varying the ``max_depth`` parameter, , which forces the tree learning algorithm to stop after at most that many levels.  Test ``max_depth`` values in the range {1, 2, 3, ..., 16}, and plot the training and validation error rates versus ``max_depth``.\n",
    "Do models with higher ``max_depth`` have higher or lower complexity?\n",
    "What choice of ``max_depth`` provides the best decision tree model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0a6581f5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0bf854e"
   },
   "source": [
    "#### Problem 2.4\n",
    "The ``min_samples_leaf`` parameter  controls the complexity of decision trees by lower bounding the amount of data required to split nodes when learning.  Fixing ``max_depth=100``, compute and plot the training and validation error rates for ``min_samples_leaf`` values in the range\n",
    "``{2**0, 2**1, 2**2, ... 2**17}``.\n",
    "Do models with higher ``min_samples_leaf`` have higher or lower complexity?\n",
    "What choice of ``min_samples_leaf`` provides the best decision tree model?\n",
    "Is this model better or worse than your depth-controlled model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3c884a0c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5b1e29f"
   },
   "source": [
    "<div>\n",
    "    <img src=\"data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22UTF-8%22%20standalone%3D%22no%22%3F%3E%0A%3C%21DOCTYPE%20svg%20PUBLIC%20%22-//W3C//DTD%20SVG%201.1//EN%22%20%22http%3A//www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd%22%3E%0A%3Csvg%20stroke-miterlimit%3D%2210%22%20style%3D%22fill-rule%3Anonzero%3Bclip-rule%3Aevenodd%3Bstroke-linecap%3Around%3Bstroke-linejoin%3Around%3B%22%20version%3D%221.1%22%20viewBox%3D%220%200%20288%2072%22%20xml%3Aspace%3D%22preserve%22%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20xmlns%3Axlink%3D%22http%3A//www.w3.org/1999/xlink%22%3E%0A%3Cdefs/%3E%0A%3Cg%20id%3D%22Layer-1%22%3E%0A%3Cpath%20d%3D%22M34.042%2035.8741C45.8469%2023.244%2031.1794%2022.6473%2024.2857%2024.1167C17.3921%2025.5861-0.960215%2033.2987%206.07817%2043.4256C13.1166%2053.5525%2023.0237%2056.9377%2052.2446%2053.4091C81.4656%2049.8804%2097.2436%2032.811%20122.962%2029.3111C148.681%2025.8112%20155.118%2039.4093%20155.118%2039.4093%22%20fill%3D%22none%22%20opacity%3D%221%22%20stroke%3D%22%23000000%22%20stroke-linecap%3D%22butt%22%20stroke-linejoin%3D%22round%22%20stroke-width%3D%223%22/%3E%0A%3Cpath%20d%3D%22M254.053%2040.6889C242.328%2053.1071%20256.999%2053.6247%20263.883%2052.1549C270.768%2050.685%20289.071%2043.0512%20281.969%2033.1691C274.868%2023.287%20264.94%2020.0179%20235.741%2023.6051C206.543%2027.1922%20190.872%2043.9744%20165.176%2047.5176C139.48%2051.0607%20132.957%2037.7776%20132.957%2037.7776%22%20fill%3D%22none%22%20opacity%3D%221%22%20stroke%3D%22%23000000%22%20stroke-linecap%3D%22butt%22%20stroke-linejoin%3D%22round%22%20stroke-width%3D%223%22/%3E%0A%3C/g%3E%0A%3C/svg%3E%0A\" width=\"200\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d107dece"
   },
   "source": [
    "## Problem 3: Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ece17c18"
   },
   "source": [
    "Although ``scikit`` has its own implementations of bagging estimators and random forests, here we will build a random forest model manually, for illustration.\n",
    "\n",
    "Random Forests are bagged collections of decision trees, which select their decision nodes from randomly chosen subsets of the possible features (rather than all features).  You can implement this easily in ``DecisionTreeClassifier`` using option ``max_features=n``, where ``n`` is the number of features to select from. Since you have ~ 14 features, you might choose, say, ``n=10``; smaller values of ``n`` will make each tree more random, but may require you to have a high maximum depth to ensure you still fit the data effectively.\n",
    "You'll write a for-loop to build the ensemble members, and another to compute the prediction of the ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce482bc4"
   },
   "source": [
    "#### Problem 3.1\n",
    "\n",
    "Using your previous split of the data into training & validation sets,\n",
    "learn a bagged ensemble of decision trees on the training data;\n",
    "then in the next part, you will evaluate the validation performance of the ensemble.\n",
    "(See the pseudocode from lecture slides.)\n",
    "For your individual learners, use parameters that will not constrain the complexity of the resulting tree very much  (e.g., set your depth cutoff >= 15, min leaf 1-4, etc.), since the bagging will be used to control overfitting instead.\n",
    "\n",
    "You will implement bootstrap sampling yourself (again, see pseudocode); simply generate $m'$ data indices uniformly with replacement, using ``numpy`` functions or simply ``rand`` and conversion to integers.\n",
    "For your bootstrap process, draw the same number of data as in your training set after the\n",
    "validation split (i.e., set $m' = m$, the number of training data).\n",
    "\n",
    "Learn at least 50 ensemble members, as you will use them in the next part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30b7e804"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78a93a66"
   },
   "source": [
    "#### Problem 3.2\n",
    "\n",
    "Plot the training and validation error of the ensemble as a function of the number of learners $B$ that you include in the ensemble, for (at least) values $B \\in \\{1,5,10,25,50\\}$.  (Just use the first $B$ learners that you trained in part 1.)\n",
    "\n",
    "Remember that your ensemble predicts by making a prediction for each member model, and then taking a vote among the $B$ models.  Since your target classes are +1 and -1, as in the slide pseudocode, to find the outcome of the vote you can simply check whether the average of the class predictions is positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2428ddfb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d09a6bf"
   },
   "source": [
    "<div>\n",
    "    <img src=\"data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22UTF-8%22%20standalone%3D%22no%22%3F%3E%0A%3C%21DOCTYPE%20svg%20PUBLIC%20%22-//W3C//DTD%20SVG%201.1//EN%22%20%22http%3A//www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd%22%3E%0A%3Csvg%20stroke-miterlimit%3D%2210%22%20style%3D%22fill-rule%3Anonzero%3Bclip-rule%3Aevenodd%3Bstroke-linecap%3Around%3Bstroke-linejoin%3Around%3B%22%20version%3D%221.1%22%20viewBox%3D%220%200%20288%2072%22%20xml%3Aspace%3D%22preserve%22%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20xmlns%3Axlink%3D%22http%3A//www.w3.org/1999/xlink%22%3E%0A%3Cdefs/%3E%0A%3Cg%20id%3D%22Layer-1%22%3E%0A%3Cpath%20d%3D%22M34.042%2035.8741C45.8469%2023.244%2031.1794%2022.6473%2024.2857%2024.1167C17.3921%2025.5861-0.960215%2033.2987%206.07817%2043.4256C13.1166%2053.5525%2023.0237%2056.9377%2052.2446%2053.4091C81.4656%2049.8804%2097.2436%2032.811%20122.962%2029.3111C148.681%2025.8112%20155.118%2039.4093%20155.118%2039.4093%22%20fill%3D%22none%22%20opacity%3D%221%22%20stroke%3D%22%23000000%22%20stroke-linecap%3D%22butt%22%20stroke-linejoin%3D%22round%22%20stroke-width%3D%223%22/%3E%0A%3Cpath%20d%3D%22M254.053%2040.6889C242.328%2053.1071%20256.999%2053.6247%20263.883%2052.1549C270.768%2050.685%20289.071%2043.0512%20281.969%2033.1691C274.868%2023.287%20264.94%2020.0179%20235.741%2023.6051C206.543%2027.1922%20190.872%2043.9744%20165.176%2047.5176C139.48%2051.0607%20132.957%2037.7776%20132.957%2037.7776%22%20fill%3D%22none%22%20opacity%3D%221%22%20stroke%3D%22%23000000%22%20stroke-linecap%3D%22butt%22%20stroke-linejoin%3D%22round%22%20stroke-width%3D%223%22/%3E%0A%3C/g%3E%0A%3C/svg%3E%0A\" width=\"200\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Shattering & VC Dimension\n",
    "\n",
    "Consider the following four \"datasets\", which have two real-valued features $x_1,x_2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(12, 3))\n",
    "x = np.array([[2,2],[4,8],[6,3],[8,6]])\n",
    "for i in range(4): \n",
    "    axes[i].plot(x[:i+1,0],x[:i+1,1],'ro',ms=8); axes[i].axis([0,10,0,10]); axes[i].set_title(f'({i+1})')\n",
    "    axes[i].set_xticks(np.unique(x[:,0])); axes[i].set_yticks(np.unique(x[:,1])); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note that no three of the four points are co-linear.)\n",
    "\n",
    "For each of the learners listed below, answer **(a)** which of the four data sets **can be shattered** by a learner of that form?  Give a brief explanation / justification (1-2 sentences). Then use your results to **(b)** guess the VC dimension of the classifier (you do not have to give a formal proof, just your reasoning).\n",
    "\n",
    "In each learner, the parameters $a,b,c,\\ldots$ are real-valued scalars, and $T[z]$ is the sign threshold function, i.e., $T[z]=+1$ for $z\\geq 0$ and $T[z] = -1$ for $z<0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $T(\\ a + b \\ x_1 \\ )$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) which data sets & why? \n",
    "# (b) VC dimension guess?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $T(\\ (a*b)\\ x_1 + (c/a) \\ x_2 \\ )$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) which data sets & why? \n",
    "# (b) VC dimension guess?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $T(\\ (x_1-a)^2 + (x_2 -b)^2 - c \\ )$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) which data sets & why? \n",
    "# (b) VC dimension guess?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Credit:\n",
    "* $T(\\ a + b\\,x_1 + c\\,x_2 \\ ) \\times T(\\ d + b\\,x_1 + c\\,x_2 \\ )$\n",
    "  - **Hint:** the two linear equations correspond to two parallel lines, since both have the same coefficients for $x_1$ and $x_2$.  Then, $T(z)\\times T(z') = +1$ if and only if $z$ and $z'$ have the same sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) which data sets & why? \n",
    "# (b) VC dimension guess?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d09a6bf"
   },
   "source": [
    "<div>\n",
    "    <img src=\"data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22UTF-8%22%20standalone%3D%22no%22%3F%3E%0A%3C%21DOCTYPE%20svg%20PUBLIC%20%22-//W3C//DTD%20SVG%201.1//EN%22%20%22http%3A//www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd%22%3E%0A%3Csvg%20stroke-miterlimit%3D%2210%22%20style%3D%22fill-rule%3Anonzero%3Bclip-rule%3Aevenodd%3Bstroke-linecap%3Around%3Bstroke-linejoin%3Around%3B%22%20version%3D%221.1%22%20viewBox%3D%220%200%20288%2072%22%20xml%3Aspace%3D%22preserve%22%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20xmlns%3Axlink%3D%22http%3A//www.w3.org/1999/xlink%22%3E%0A%3Cdefs/%3E%0A%3Cg%20id%3D%22Layer-1%22%3E%0A%3Cpath%20d%3D%22M34.042%2035.8741C45.8469%2023.244%2031.1794%2022.6473%2024.2857%2024.1167C17.3921%2025.5861-0.960215%2033.2987%206.07817%2043.4256C13.1166%2053.5525%2023.0237%2056.9377%2052.2446%2053.4091C81.4656%2049.8804%2097.2436%2032.811%20122.962%2029.3111C148.681%2025.8112%20155.118%2039.4093%20155.118%2039.4093%22%20fill%3D%22none%22%20opacity%3D%221%22%20stroke%3D%22%23000000%22%20stroke-linecap%3D%22butt%22%20stroke-linejoin%3D%22round%22%20stroke-width%3D%223%22/%3E%0A%3Cpath%20d%3D%22M254.053%2040.6889C242.328%2053.1071%20256.999%2053.6247%20263.883%2052.1549C270.768%2050.685%20289.071%2043.0512%20281.969%2033.1691C274.868%2023.287%20264.94%2020.0179%20235.741%2023.6051C206.543%2027.1922%20190.872%2043.9744%20165.176%2047.5176C139.48%2051.0607%20132.957%2037.7776%20132.957%2037.7776%22%20fill%3D%22none%22%20opacity%3D%221%22%20stroke%3D%22%23000000%22%20stroke-linecap%3D%22butt%22%20stroke-linejoin%3D%22round%22%20stroke-width%3D%223%22/%3E%0A%3C/g%3E%0A%3C/svg%3E%0A\" width=\"200\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cfad271"
   },
   "source": [
    "---\n",
    "### Statement of Collaboration (5 points)\n",
    "\n",
    "It is **mandatory** to include a Statement of Collaboration in each submission, with respect to the guidelines below. Include the names of everyone involved in the discussions (especially in-person ones), and what was discussed.\n",
    "\n",
    "All students are required to follow the academic honesty guidelines posted on the course website. For\n",
    "programming assignments, in particular, I encourage the students to organize (perhaps using EdD) to\n",
    "discuss the task descriptions, requirements, bugs in my code, and the relevant technical content before they start\n",
    "working on it. However, you should not discuss the specific solutions, and, as a guiding principle, you are not\n",
    "allowed to take anything written or drawn away from these discussions (i.e. no photographs of the blackboard,\n",
    "written notes, referring to EdD, etc.). Especially after you have started working on the assignment, try\n",
    "to restrict the discussion to EdD as much as possible, so that there is no doubt as to the extent of your\n",
    "collaboration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ff1eeb6f"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
